{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = pickle.load(open(\"random_forest_model.sav\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = pd.read_csv(\"processed_train_data.csv\")\n",
    "training_targets = training_data[\"revenue\"]\n",
    "training_data.drop([\"Unnamed: 0\",\"revenue\"],axis = 1,inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n"
     ]
    }
   ],
   "source": [
    "cols = training_data.columns\n",
    "print(len(cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importance of P29 is 0.222021\n",
      "Feature importance of Years Open is 0.199540\n",
      "Feature importance of P28 is 0.061920\n",
      "Feature importance of P20 is 0.041254\n",
      "Feature importance of P23 is 0.034180\n",
      "Feature importance of P6 is 0.034115\n",
      "Feature importance of P22 is 0.030476\n",
      "Feature importance of P17 is 0.027760\n",
      "Feature importance of P19 is 0.026481\n",
      "Feature importance of P2 is 0.025714\n",
      "Feature importance of P1 is 0.024516\n",
      "Feature importance of P5 is 0.023115\n",
      "Feature importance of P21 is 0.021092\n",
      "Feature importance of P11 is 0.020605\n",
      "Feature importance of P12 is 0.017910\n",
      "Feature importance of P3 is 0.014886\n",
      "Feature importance of P8 is 0.013702\n",
      "Feature importance of P4 is 0.012877\n",
      "Feature importance of P10 is 0.012180\n",
      "Feature importance of P25 is 0.011336\n",
      "Feature importance of P13 is 0.010841\n",
      "Feature importance of P27 is 0.010533\n",
      "Feature importance of FC is 0.010219\n",
      "Feature importance of IL is 0.007023\n",
      "Feature importance of Big Cities is 0.006748\n",
      "Feature importance of P9 is 0.006601\n",
      "Feature importance of P14 is 0.006477\n",
      "Feature importance of Other is 0.006238\n",
      "Feature importance of P26 is 0.006011\n",
      "Feature importance of P32 is 0.005630\n",
      "Feature importance of P18 is 0.005048\n",
      "Feature importance of P36 is 0.004942\n",
      "Feature importance of P37 is 0.004931\n",
      "Feature importance of P33 is 0.004774\n",
      "Feature importance of P15 is 0.004588\n",
      "Feature importance of P16 is 0.004275\n",
      "Feature importance of P31 is 0.004139\n",
      "Feature importance of P24 is 0.004055\n",
      "Feature importance of P34 is 0.003949\n",
      "Feature importance of P30 is 0.003585\n",
      "Feature importance of P35 is 0.002235\n",
      "Feature importance of P7 is 0.001465\n",
      "Feature importance of DT is 0.000012\n"
     ]
    }
   ],
   "source": [
    "importances = model.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "for i in indices:\n",
    "    print(\"Feature importance of %s is %f\" %(cols[i],importances[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['P29' 'Years Open' 'P28' 'P20' 'P23' 'P6' 'P22' 'P17' 'P19' 'P2']\n"
     ]
    }
   ],
   "source": [
    "top_features = np.array(cols[indices[:10]])\n",
    "print(top_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(137, 10)\n"
     ]
    }
   ],
   "source": [
    "train_data = training_data[top_features]\n",
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   P29  Years Open  P28  P20  P23  P6  P22  P17  P19   P2\n",
      "0  3.0          19  2.0    4    3   2    3    2    5  5.0\n",
      "1  3.0          10  3.0    2    2   2    3    0    3  5.0\n",
      "2  3.0           5  1.0    1    1   3    1    0    1  4.0\n",
      "3  7.5           6  2.5   12   10   4    1    3   20  4.5\n",
      "4  3.0           9  1.0    2    1   2    2    1    2  4.0\n"
     ]
    }
   ],
   "source": [
    "print(train_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_data = pd.read_csv(\"processed_test_data.csv\")\n",
    "testing_data.drop(\"Unnamed: 0\",axis = 1,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 43)\n",
      "   P1   P2   P3   P4  P5  P6  P7  P8  P9  P10 ...  P34  P35  P36  P37  \\\n",
      "0   1  4.0  4.0  4.0   1   2   5   4   5    5 ...    0    0    0    0   \n",
      "1   3  4.0  4.0  4.0   2   2   5   3   4    4 ...    0    0    0    0   \n",
      "2   3  4.0  4.0  4.0   2   2   5   4   4    5 ...    0    0    0    0   \n",
      "3   2  4.0  4.0  4.0   2   3   5   4   5    4 ...    0    0    0    0   \n",
      "4   2  4.0  4.0  4.0   1   2   5   4   5    4 ...    0    0    0    0   \n",
      "\n",
      "   Years Open  Big Cities  Other  DT  FC  IL  \n",
      "0           7           0      1   0   1   0  \n",
      "1           7           0      1   0   0   1  \n",
      "2           5           1      0   0   1   0  \n",
      "3           5           0      1   0   0   1  \n",
      "4           5           0      1   0   1   0  \n",
      "\n",
      "[5 rows x 43 columns]\n"
     ]
    }
   ],
   "source": [
    "print(testing_data.shape)\n",
    "print(testing_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 10)\n"
     ]
    }
   ],
   "source": [
    "test_data = testing_data[top_features]\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   P29  Years Open  P28  P20  P23  P6  P22  P17  P19   P2\n",
      "0  3.0           7  2.0    5    4   2    1    2    5  4.0\n",
      "1  3.0           7  1.0    5    1   2    2    0    5  4.0\n",
      "2  3.0           5  2.0    5    5   2    5    0    5  4.0\n",
      "3  3.0           5  2.0    4    2   3    2    0    4  4.0\n",
      "4  3.0           5  5.0    5    1   2    1    0    1  4.0\n"
     ]
    }
   ],
   "source": [
    "print(test_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "model = RandomForestRegressor(n_estimators = 1000,n_jobs = -1)\n",
    "fit = model.fit(train_data,training_targets)\n",
    "predictions = model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = \"random_forest_selected.sav\"\n",
    "pickle.dump(model,open(filename,\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Revenue\n",
      "0  4353922.906\n",
      "1  3334523.742\n",
      "2  3399228.675\n",
      "3  2916814.925\n",
      "4  4684316.184\n"
     ]
    }
   ],
   "source": [
    "final = pd.DataFrame(predictions,columns = [\"Revenue\"])\n",
    "print(final.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final.to_csv(\"select_features_prediction.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_variables = len(top_features)\n",
    "\n",
    "def basic_model():\n",
    "    nn_model = Sequential()\n",
    "    nn_model.add(Dense(num_variables,input_dim = num_variables,activation = \"relu\"))\n",
    "    nn_model.add(Dense(1))\n",
    "    nn_model.compile(loss = \"mean_squared_error\",optimizer = \"adam\")\n",
    "    return nn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(137, 10)\n",
      "(137,)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "print(training_targets.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
